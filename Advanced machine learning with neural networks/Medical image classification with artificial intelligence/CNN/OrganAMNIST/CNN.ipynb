{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\metho\\.medmnist\\pneumoniamnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\metho\\.medmnist\\pneumoniamnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\metho\\.medmnist\\pneumoniamnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\metho\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\metho\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.2502 Acc: 0.9048\n",
      "val Loss: 0.1158 Acc: 0.9504\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.1397 Acc: 0.9480\n",
      "val Loss: 0.2289 Acc: 0.9084\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.1451 Acc: 0.9467\n",
      "val Loss: 0.1875 Acc: 0.9237\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.1187 Acc: 0.9543\n",
      "val Loss: 0.0855 Acc: 0.9656\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1052 Acc: 0.9567\n",
      "val Loss: 0.0877 Acc: 0.9714\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1066 Acc: 0.9607\n",
      "val Loss: 0.1448 Acc: 0.9351\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1090 Acc: 0.9592\n",
      "val Loss: 0.2065 Acc: 0.9370\n",
      "Epoch 7/24\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import Lambda\n",
    "import medmnist\n",
    "import copy\n",
    "from medmnist import INFO, Evaluator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 下载并加载PneumoniaMNIST数据集\n",
    "data_flag = 'organamnist'\n",
    "download = True\n",
    "\n",
    "info = INFO[data_flag]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "# 数据增强和转换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    transforms.Normalize(mean=[.5], std=[.5]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(28, scale=(0.8, 1.0))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
    "val_dataset = DataClass(split='val', transform=test_transform, download=download)\n",
    "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 加载预训练的ResNet模型并增加Dropout\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# 修改最后的全连接层以适应二分类任务（肺炎与非肺炎）\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(num_ftrs, 2)\n",
    ")\n",
    "\n",
    "# 将模型移动到GPU或CPU\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=25, model_path='best_model.pth'):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 每个epoch都有训练和验证阶段\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 训练模式\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()   # 验证模式\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 遍历数据\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).squeeze().long()  # 确保labels是1D张量\n",
    "\n",
    "                # 清零梯度\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 前向传播\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # 反向传播 + 优化\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 统计\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # 深度复制模型\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, model_path)  # 保存最佳模型权重\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # 加载最佳模型权重\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# 训练模型\n",
    "model = train_model(model, criterion, optimizer, num_epochs=25, model_path='best_model.pth')\n",
    "\n",
    "def test_model(model, test_loader, model_path='best_model.pth'):\n",
    "    model.load_state_dict(torch.load(model_path))  # 加载最佳模型权重\n",
    "    model.eval()  # 设定为评估模式\n",
    "    running_corrects = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_features = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).long().squeeze()  # 确保labels是1D张量\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_features.extend(outputs.cpu().numpy())  # 获取特征输出\n",
    "\n",
    "    acc = running_corrects.double() / len(test_loader.dataset)\n",
    "    print(f'Test Acc: {acc:.4f}')\n",
    "\n",
    "    # 生成混淆矩阵和分类报告\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    cr = classification_report(all_labels, all_preds, target_names=['Non-Pneumonia', 'Pneumonia'], digits=4)\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    print('Classification Report:')\n",
    "    print(cr)\n",
    "\n",
    "    # 绘制混淆矩阵热力图\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Pneumonia', 'Pneumonia'], yticklabels=['Non-Pneumonia', 'Pneumonia'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # PCA降维\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(all_features)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(pca_result[:, 0], pca_result[:, 1], c=all_labels, cmap='viridis', alpha=0.5)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.title('PCA of Test Data')\n",
    "    plt.show()\n",
    "\n",
    "# 测试模型\n",
    "test_model(model, test_loader, model_path='best_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
